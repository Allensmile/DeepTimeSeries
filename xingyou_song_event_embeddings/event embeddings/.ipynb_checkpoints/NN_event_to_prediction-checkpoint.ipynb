{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import nltk \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "\n",
    "with open('word_embeddings/run_info.p', 'r') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "info2index = x['info2index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "event_embeddings = pd.read_csv(\"word_embeddings/u_epoch_900.csv\", header = None)\n",
    "embedding_lst = []\n",
    "for row in event_embeddings.iterrows():\n",
    "    index, data = row \n",
    "    temp = data.tolist()\n",
    "    actual_data = [float(x) for x in temp[0].split()]\n",
    "    embedding_lst.append(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stock_to_events = {}\n",
    "for key_ in info2index:\n",
    "    stock_ = key_[0]\n",
    "    embedding_to_index = info2index[key_]\n",
    "    date_ = key_[1]\n",
    "    event = key_[2]\n",
    "    new_value = [date_, embedding_to_index]\n",
    "    if stock_ in stock_to_events: \n",
    "        stock_to_events[stock_].append(new_value)\n",
    "    else:\n",
    "        stock_to_events[stock_] = [new_value]\n",
    "\n",
    "for stock_ in stock_to_events:\n",
    "    stock_to_events[stock_] = sorted( stock_to_events[stock_], key = lambda x: x[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOOGL', 'INTC', 'AAPL', 'CSCO', 'AMD', 'QCOM', 'NVDA', 'AMZN', 'MSFT', 'IBM']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_to_events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    stock_length = {}\n",
    "    stock_length[\"Number of Articles\"] = len(stock_to_events[stock])\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stk_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Number of Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IBM</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Number of Articles\n",
       "0      GOOGL                 528\n",
       "1       INTC                 409\n",
       "2       AAPL                2292\n",
       "3       CSCO                 229\n",
       "4        AMD                  23\n",
       "5       QCOM                 351\n",
       "6       NVDA                  54\n",
       "7       AMZN                1062\n",
       "8       MSFT                 830\n",
       "9        IBM                 415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ [\"Stock Name\", \"Number of Articles\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def up_down_ratio(stock, day_lag): #ex: sentiment_to_price_plot(\"AAPL\", 1, 'neg')\n",
    "    stock_data = news_csv[news_csv[\"stock\"] == stock]\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    total = []\n",
    "    for index, row in stock_data.iterrows():\n",
    "    \n",
    "\n",
    "        day = conv_num_to_string(str(row[\"date\"]) )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            \n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            #print next_price[\"Date\"], google_price_csv.iloc[row_index][\"Date\"]\n",
    "            diff = next_price[\"Close\"] - next_price[\"Open\"]\n",
    "            if diff >= 0.0:\n",
    "                total.append(1) \n",
    "            else:\n",
    "                total.append(0)\n",
    "    return 100*sum(total)/len(total)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_down_ratio(\"AAPL\", 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    if stock != 'IBM':\n",
    "        stock_length = {}\n",
    "        stock_length[\"Price Up Percentage\"] = up_down_ratio(stock, 1)\n",
    "        stock_length[\"Stock Name\"] = stock\n",
    "        stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Price Up Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Price Up Percentage\n",
       "0      GOOGL                   49\n",
       "1       INTC                   49\n",
       "2       AAPL                   48\n",
       "3       CSCO                   60\n",
       "4        AMD                   50\n",
       "5       QCOM                   45\n",
       "6       NVDA                   72\n",
       "7       AMZN                   48\n",
       "8       MSFT                   51"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\", \"Price Up Percentage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])\n",
    "google_price_csv = pd.read_csv(\"price_data/GOOGL_2006-01-01_to_2017-11-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_to_month = {\"01\": \"Jan\", \"02\":\"Feb\", \"03\":\"Mar\", \"04\":\"Apr\", \"05\":\"May\", \"06\": \"Jun\", \"07\":\"Jul\", \"08\":\"Aug\", \"09\":\"Sep\", \"10\":\"Oct\", \"11\":\"Nov\", \"12\":\"Dec\"}\n",
    "def conv_num_to_string(d): #ex: conv_num_to_string('20041001') = '01-Oct-04'\n",
    "    year = d[0:4]\n",
    "    month = d[4:6]\n",
    "    day = d[6:8]\n",
    "    new = day + \"-\" + number_to_month[month] + \"-\" + year[2:4]\n",
    "    return new \n",
    "\n",
    "def numeric_day_distance(day1, day2): #'20140111', '20150115'\n",
    "    d0 = date(int(day1[0:4]), int(day1[4:6]), int(day1[6:8]) )\n",
    "    d1 = date(int(day2[0:4]), int(day2[4:6]), int(day2[6:8]) )\n",
    "    delta = d0 - d1 \n",
    "    return abs(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "def short_term_embedding_to_class(stock, day_lag, hidden_size, learning_rate, num_epochs, batch_size, training_ratio): #ex: sentiment_to_price_plot(\"AAPL\", 1, 'neg')\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for event in stock_to_events[stock]:\n",
    "        \n",
    "        \n",
    "        day = conv_num_to_string( event[0]    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp_x.append( embedding_lst[event[1]]  )\n",
    "            \n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            \n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "            \n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------\n",
    "    \n",
    "    input_size = 100\n",
    "#     hidden_size = 150\n",
    "#     learning_rate = 0.001\n",
    "#     num_epochs = 10\n",
    "#     batch_size = 100\n",
    "    \n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "    \n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "    \n",
    "    train_x = torch.FloatTensor(train_x)\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    \n",
    "    \n",
    "    test_x = torch.FloatTensor(test_x)\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    \n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "    \n",
    "    \n",
    "    test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "    \n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size, hidden_size)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out) \n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, hidden_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader):\n",
    "            \n",
    "            inp = Variable(inp)\n",
    "            outp = Variable(outp)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            \n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_error = float(correct)/total \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_error = float(correct)/total \n",
    "    \n",
    "    print train_error, test_error\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.560344827586 0.481617647059\n"
     ]
    }
   ],
   "source": [
    "short_term_embedding_to_class('GOOGL', 1, 120, 0.001, 10, 100, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def total_embedding_to_class(stock, training_ratio): \n",
    "\n",
    "\n",
    "    #----------------------------LAGS\n",
    "    day_lag = 1 \n",
    "    week_lag = 7\n",
    "    month_lag = 30\n",
    "    #--------------------------- NN parameters\n",
    "    input_size = 100\n",
    "    window_size_convM =3\n",
    "    hidden_size_convM = 20\n",
    "\n",
    "    window_size_convL =3 \n",
    "    hidden_size_convL = 40\n",
    "\n",
    "\n",
    "    hidden_size_end = 200\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    #training_ratio = 0.8\n",
    "    #stock = 'AAPL'\n",
    "\n",
    "    #----------------------------------- PARAMTETRS\n",
    "\n",
    "\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for i in range(len(stock_to_events[stock]) ):\n",
    "        event = stock_to_events[stock][i]\n",
    "\n",
    "\n",
    "        date_numeric = event[0]\n",
    "        day = conv_num_to_string( date_numeric    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp = {}\n",
    "            temp[\"day\"] = embedding_lst[event[1]]\n",
    "\n",
    "\n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "\n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "\n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "\n",
    "\n",
    "\n",
    "            temp[\"week\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= week_lag ) :\n",
    "                temp['week'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "\n",
    "            temp[\"month\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= month_lag ) :\n",
    "                temp['month'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "            temp_x.append(temp)\n",
    "    #--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "\n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "\n",
    "\n",
    "    max_event_length_week = max([len(day_embedding[\"week\"]) for day_embedding in temp_x ])\n",
    "    max_event_length_month = max([len(day_embedding[\"month\"]) for day_embedding in temp_x ])\n",
    "\n",
    "\n",
    "    train_x_concatenate = []\n",
    "\n",
    "\n",
    "\n",
    "    for day_embedding in train_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        train_x_concatenate.append(block)\n",
    "\n",
    "    train_x_concatenate = torch.FloatTensor(train_x_concatenate)\n",
    "\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    train_x_concatenate_temp = torch.utils.data.TensorDataset(train_x_concatenate, train_y)\n",
    "    train_loader_total = torch.utils.data.DataLoader(dataset=train_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------\n",
    "\n",
    "    test_x_concatenate = []\n",
    "\n",
    "\n",
    "    for day_embedding in test_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        test_x_concatenate.append(block)\n",
    "\n",
    "\n",
    "    test_x_concatenate = torch.FloatTensor(test_x_concatenate)\n",
    "\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    test_x_concatenate_temp = torch.utils.data.TensorDataset(test_x_concatenate, test_y)\n",
    "    test_loader_total = torch.utils.data.DataLoader(dataset=test_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size + hidden_size_convM + hidden_size_convL , hidden_size_end)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size_end, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "\n",
    "            self.convM = nn.Conv1d(max_event_length_week, hidden_size_convM, window_size_convM, padding = 1 )\n",
    "            self.poolM = nn.MaxPool1d(input_size)\n",
    "\n",
    "            self.convL = nn.Conv1d(max_event_length_month, hidden_size_convL, window_size_convL, padding = 1 )\n",
    "            self.poolL = nn.MaxPool1d(input_size)\n",
    "\n",
    "        def forward(self, giant_block):\n",
    "\n",
    "            S = giant_block[:, 0,]\n",
    "\n",
    "            M = giant_block[:,1: max_event_length_week+1,].contiguous()\n",
    "\n",
    "            L = giant_block[:,max_event_length_week+1:,].contiguous()\n",
    "\n",
    "            #--------------------LARGE\n",
    "\n",
    "            out_L = self.convL(L)\n",
    "            out_L = self.poolL(out_L)\n",
    "            out_L = out_L.view(-1, hidden_size_convL)\n",
    "            #-------------------LARGE\n",
    "\n",
    "            #------------------- MIDDLE\n",
    "            out_M = self.convM(M)\n",
    "            out_M = self.poolM(out_M)\n",
    "            out_M = out_M.view(-1, hidden_size_convM)\n",
    "            #-------------------MIDDLE\n",
    "\n",
    "\n",
    "            #x = concatenation S, M, L\n",
    "            x = torch.cat((out_L, out_M,S, ), 1) \n",
    "\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out)\n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader_total):\n",
    "\n",
    "            inp = Variable(inp, requires_grad=True)\n",
    "            outp = Variable(outp)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader_total:\n",
    "        inp = Variable(inp)\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader_total:\n",
    "        inp = Variable(inp, requires_grad=True )\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "\n",
    "    print train_accuracy, test_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_embedding_to_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-33b9ba9f7900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_embedding_to_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CSCO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'total_embedding_to_class' is not defined"
     ]
    }
   ],
   "source": [
    "total_embedding_to_class('CSCO', 0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
